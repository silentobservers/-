包含基于gym中小车倒立摆环境的DQN代码，用于对答辩中自己的陈述证明。

“十万次学习”中，一次学习的定义是什么？十万次学习需要多长时间？
认真听取老师的意见，针对论文用词不恰当而产生意义不明确的地方，在此修正和阐明。
“十万次学习”指的是神经网络进行了“十万次参数更新”。根据神经网络的训练原理，利用的是误差反向传播方法对网络中的参数进行更行。对神经网络参数更新的这一过程，通常可以成为神经网络的学习和训练。综上所述，原文中的“十万次学习”，含义是用来决策的神经网络，利用训练样本，通过损失函数表达式计算误差，利用误差反向传播方法对神经网络的参数进行了十万次更新。
并且，本论文指出，在小车倒立摆和小车爬山实验中，神经网络的规模较小（包含三层隐含层，每层含有256个神经单元，前两层使用了ReLU激活函数，第三层为线性全连接层，且使用的是专门为神经网络优化的tensorflow平台），所以无论是前向传播还是反向误差传播的计算速度都非常快。同时，实验是在gym仿真环境下进行的，所以仿真中被控对象的模型可以根据由gym提供的离散动力学模型快速计算，可以认为仿真的速度与电脑cpu的频率成正比，因此所花费的时间同样很少。综上所述，“十万次学习”，或者说“十万次参数更新”，在小车倒立摆中，所花费的时间是十几分钟。为了更加严谨地呈现结果，作者重复了5次实验，验证自己的陈述。在小车倒立摆中进行了十万次参数更新，对实验平台的cpu，以及每次实验的时间进行记录，结果如下：
cpu:  1.6 GHz
time_cost(5 times running):  [14.418425679206848, 16.069868584473927, 17.214702518781028, 20.155413508415222, 20.320535226662955]  min
average time per running:  17.635789103507996  min
试验结果表明，完成“10万次参数更新”仅需约17.6分钟。由于本人的笔记本性能有限，主频最高仅1.6 GHz且不能睿频，大部分电脑主频都在2.0 GHz以上，所以完成“10万次次参数更新”需要十几分钟是真实成立的。

![image](https://github.com/silentobservers/proof-for-cartpole-results-in-my-thesis/blob/master/pictures/1.jpg)
